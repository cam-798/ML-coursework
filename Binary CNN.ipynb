{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d557e5",
   "metadata": {},
   "source": [
    "<h5>Importing libraries</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4462fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "# Machine learning (non deep learning)\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#misc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e2fa",
   "metadata": {},
   "source": [
    "<h5>Read in images into numpy arrays and record type of tumor with one hot encoder</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d892ca2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"dataset/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"dataset/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[1]]).toarray())\n",
    "        \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/no_tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435ded4",
   "metadata": {},
   "source": [
    "<h5>Reshape data and split between test and train data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf006ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "result = np.array(result)\n",
    "result = result.reshape(3000,2)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf30598",
   "metadata": {},
   "source": [
    "<h5>Build the CNN model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abb2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(32, 32, 1), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',  metrics = ['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c1090",
   "metadata": {},
   "source": [
    "<h5>Train the model and record time to train</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ecb8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/60 [==============================] - 4s 56ms/step - loss: 0.9648 - accuracy: 0.8396 - val_loss: 1.4872 - val_accuracy: 0.2750\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.3312 - accuracy: 0.8838 - val_loss: 0.2906 - val_accuracy: 0.8833\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.2521 - accuracy: 0.9013 - val_loss: 0.2285 - val_accuracy: 0.9083\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2249 - accuracy: 0.9104 - val_loss: 0.1846 - val_accuracy: 0.9300\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2038 - accuracy: 0.9200 - val_loss: 0.1497 - val_accuracy: 0.9417\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.1556 - accuracy: 0.9329 - val_loss: 0.1334 - val_accuracy: 0.9417\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.1670 - accuracy: 0.9321 - val_loss: 0.1149 - val_accuracy: 0.9450\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.1447 - accuracy: 0.9396 - val_loss: 0.1053 - val_accuracy: 0.9550\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.1373 - accuracy: 0.9442 - val_loss: 0.1194 - val_accuracy: 0.9450\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.1198 - accuracy: 0.9496 - val_loss: 0.0948 - val_accuracy: 0.9617\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1186 - accuracy: 0.9525 - val_loss: 0.0982 - val_accuracy: 0.9583\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.1056 - accuracy: 0.9579 - val_loss: 0.0977 - val_accuracy: 0.9650\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0944 - accuracy: 0.9550 - val_loss: 0.0824 - val_accuracy: 0.9650\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0971 - accuracy: 0.9579 - val_loss: 0.0934 - val_accuracy: 0.9717\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0794 - accuracy: 0.9679 - val_loss: 0.0873 - val_accuracy: 0.9650\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0877 - accuracy: 0.9638 - val_loss: 0.1160 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.0899 - val_accuracy: 0.9617\n",
      "--- 54.934688329696655 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test), callbacks=[callback])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0f441",
   "metadata": {},
   "source": [
    "<h6>Some basic results recording, just for keeping information to hand</h6>\n",
    "\n",
    "30.509965896606445 seconds --- 30 epochs , 0.9683 acc , 16x16 Greyscale image <br>\n",
    "86.94418954849243 seconds --- 30 epochs , 0.9783 acc , 32x32 Greyscale image <br>\n",
    "169.6840739250183 seconds --- 60 epochs , 0.9667 acc , 32x32 Greyscale image <br>\n",
    "335.7380225658417 seconds --- 30 epochs , 0.9700 acc , 64x64 Greyscale image <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660a1c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9647661447525024,\n",
       "  0.33124059438705444,\n",
       "  0.2520950138568878,\n",
       "  0.22493906319141388,\n",
       "  0.20380254089832306,\n",
       "  0.15564385056495667,\n",
       "  0.16696879267692566,\n",
       "  0.1446661502122879,\n",
       "  0.1372992843389511,\n",
       "  0.1197928637266159,\n",
       "  0.11859504878520966,\n",
       "  0.10563132911920547,\n",
       "  0.09437718242406845,\n",
       "  0.09706917405128479,\n",
       "  0.07943117618560791,\n",
       "  0.0877363383769989,\n",
       "  0.07492616772651672],\n",
       " 'accuracy': [0.8395833373069763,\n",
       "  0.8837500214576721,\n",
       "  0.9012500047683716,\n",
       "  0.9104166626930237,\n",
       "  0.9200000166893005,\n",
       "  0.9329166412353516,\n",
       "  0.9320833086967468,\n",
       "  0.9395833611488342,\n",
       "  0.9441666603088379,\n",
       "  0.9495833516120911,\n",
       "  0.9524999856948853,\n",
       "  0.9579166769981384,\n",
       "  0.9549999833106995,\n",
       "  0.9579166769981384,\n",
       "  0.9679166674613953,\n",
       "  0.9637500047683716,\n",
       "  0.9725000262260437],\n",
       " 'val_loss': [1.4871598482131958,\n",
       "  0.29057687520980835,\n",
       "  0.22846278548240662,\n",
       "  0.18461869657039642,\n",
       "  0.149740532040596,\n",
       "  0.133419930934906,\n",
       "  0.11488857120275497,\n",
       "  0.10527548938989639,\n",
       "  0.11940398812294006,\n",
       "  0.09484884887933731,\n",
       "  0.09821468591690063,\n",
       "  0.09770568460226059,\n",
       "  0.08243004232645035,\n",
       "  0.09342308342456818,\n",
       "  0.0872594341635704,\n",
       "  0.11603806912899017,\n",
       "  0.0899188369512558],\n",
       " 'val_accuracy': [0.2750000059604645,\n",
       "  0.8833333253860474,\n",
       "  0.9083333611488342,\n",
       "  0.9300000071525574,\n",
       "  0.9416666626930237,\n",
       "  0.9416666626930237,\n",
       "  0.9449999928474426,\n",
       "  0.9549999833106995,\n",
       "  0.9449999928474426,\n",
       "  0.9616666436195374,\n",
       "  0.9583333134651184,\n",
       "  0.9649999737739563,\n",
       "  0.9649999737739563,\n",
       "  0.971666693687439,\n",
       "  0.9649999737739563,\n",
       "  0.9666666388511658,\n",
       "  0.9616666436195374]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3fe84",
   "metadata": {},
   "source": [
    "<h5>Read in the validation data in the same way we read in the training and testing data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2505357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "validation_data = []\n",
    "validation_result = []\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"test_dataset/test/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"test_dataset/test/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "test_encoder = OneHotEncoder()\n",
    "test_encoder.fit([[0], [1]]) \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/no_tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L') # not an RGB image so import as greyscale\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    validation_data.append(np.array(img))\n",
    "    validation_result.append(test_encoder.transform([[0]]).toarray())\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    validation_data.append(np.array(img))\n",
    "    validation_result.append(test_encoder.transform([[1]]).toarray())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21af695",
   "metadata": {},
   "source": [
    "<h5>reshape validation data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6797ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = np.array(validation_data)\n",
    "validation_result = np.array(validation_result)\n",
    "validation_result = validation_result.reshape(200,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13b402",
   "metadata": {},
   "source": [
    "<h5>Get and print scores</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11491ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(validation_data, validation_result, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86949422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.07661273330450058\n",
      "test accuracy: 0.9649999737739563\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss: \" + str(scores[0]))\n",
    "print(\"test accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498a0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
