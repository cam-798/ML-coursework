{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d557e5",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4462fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "# Machine learning (non deep learning)\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#misc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e2fa",
   "metadata": {},
   "source": [
    "Read in csv data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6e5e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_labels = pd.read_csv(\"dataset/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc7e2f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>pituitary_tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name             label\n",
       "0     IMAGE_0000.jpg  meningioma_tumor\n",
       "1     IMAGE_0001.jpg          no_tumor\n",
       "2     IMAGE_0002.jpg  meningioma_tumor\n",
       "3     IMAGE_0003.jpg      glioma_tumor\n",
       "4     IMAGE_0004.jpg  meningioma_tumor\n",
       "...              ...               ...\n",
       "2995  IMAGE_2995.jpg          no_tumor\n",
       "2996  IMAGE_2996.jpg  meningioma_tumor\n",
       "2997  IMAGE_2997.jpg      glioma_tumor\n",
       "2998  IMAGE_2998.jpg      glioma_tumor\n",
       "2999  IMAGE_2999.jpg   pituitary_tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31ff6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tumor_labels)):\n",
    "    if (tumor_labels.iloc[i][\"label\"] == \"no_tumor\"):\n",
    "        tumor_labels.iloc[i][\"label\"] = \"no tumor\"\n",
    "    else: \n",
    "        tumor_labels.iloc[i][\"label\"] = \"tumor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca5ae84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name     label\n",
       "0     IMAGE_0000.jpg     tumor\n",
       "1     IMAGE_0001.jpg  no tumor\n",
       "2     IMAGE_0002.jpg     tumor\n",
       "3     IMAGE_0003.jpg     tumor\n",
       "4     IMAGE_0004.jpg     tumor\n",
       "...              ...       ...\n",
       "2995  IMAGE_2995.jpg  no tumor\n",
       "2996  IMAGE_2996.jpg     tumor\n",
       "2997  IMAGE_2997.jpg     tumor\n",
       "2998  IMAGE_2998.jpg     tumor\n",
       "2999  IMAGE_2999.jpg     tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d892ca2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"dataset/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"dataset/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[1]]).toarray())\n",
    "        \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/no_tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bf006ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "result = np.array(result)\n",
    "result = result.reshape(3000,2)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7abb2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(32, 32, 1), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',  metrics = ['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9ecb8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 1.4094 - accuracy: 0.8100 - val_loss: 0.8631 - val_accuracy: 0.2367\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.3095 - accuracy: 0.8592 - val_loss: 0.4548 - val_accuracy: 0.8750\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.2702 - accuracy: 0.8775 - val_loss: 0.3420 - val_accuracy: 0.9050\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - 3s 45ms/step - loss: 0.2476 - accuracy: 0.8896 - val_loss: 0.2079 - val_accuracy: 0.9117\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.2389 - accuracy: 0.8896 - val_loss: 0.1885 - val_accuracy: 0.9283\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.2055 - accuracy: 0.9067 - val_loss: 0.1497 - val_accuracy: 0.9333\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.1982 - accuracy: 0.9087 - val_loss: 0.1458 - val_accuracy: 0.9367\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.1929 - accuracy: 0.9175 - val_loss: 0.1378 - val_accuracy: 0.9383\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.1825 - accuracy: 0.9233 - val_loss: 0.1295 - val_accuracy: 0.9450\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.1636 - accuracy: 0.9279 - val_loss: 0.1222 - val_accuracy: 0.9417\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.1224 - val_accuracy: 0.9483\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.1431 - accuracy: 0.9429 - val_loss: 0.1226 - val_accuracy: 0.9433\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1324 - accuracy: 0.9454 - val_loss: 0.1149 - val_accuracy: 0.9483\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.1254 - accuracy: 0.9496 - val_loss: 0.1070 - val_accuracy: 0.9500\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.1140 - accuracy: 0.9525 - val_loss: 0.1115 - val_accuracy: 0.9550\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.1176 - accuracy: 0.9492 - val_loss: 0.1065 - val_accuracy: 0.9500\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.1045 - accuracy: 0.9571 - val_loss: 0.1001 - val_accuracy: 0.9500\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0979 - accuracy: 0.9571 - val_loss: 0.0996 - val_accuracy: 0.9550\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0969 - accuracy: 0.9588 - val_loss: 0.0989 - val_accuracy: 0.9600\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0921 - accuracy: 0.9613 - val_loss: 0.0948 - val_accuracy: 0.9550\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0826 - accuracy: 0.9721 - val_loss: 0.0913 - val_accuracy: 0.9567\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0757 - accuracy: 0.9683 - val_loss: 0.1038 - val_accuracy: 0.9567\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0777 - accuracy: 0.9704 - val_loss: 0.0905 - val_accuracy: 0.9633\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0727 - accuracy: 0.9725 - val_loss: 0.0894 - val_accuracy: 0.9633\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0714 - accuracy: 0.9688 - val_loss: 0.0882 - val_accuracy: 0.9617\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0674 - accuracy: 0.9737 - val_loss: 0.0824 - val_accuracy: 0.9633\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.0969 - val_accuracy: 0.9633\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0633 - accuracy: 0.9746 - val_loss: 0.0910 - val_accuracy: 0.9633\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0490 - accuracy: 0.9821 - val_loss: 0.0997 - val_accuracy: 0.9650\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.0922 - val_accuracy: 0.9650\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0442 - accuracy: 0.9854 - val_loss: 0.0960 - val_accuracy: 0.9717\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 0.0998 - val_accuracy: 0.9633\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0401 - accuracy: 0.9850 - val_loss: 0.0921 - val_accuracy: 0.9700\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.0999 - val_accuracy: 0.9667\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0398 - accuracy: 0.9854 - val_loss: 0.0852 - val_accuracy: 0.9617\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0883 - val_accuracy: 0.9700\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0956 - val_accuracy: 0.9667\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0287 - accuracy: 0.9892 - val_loss: 0.1169 - val_accuracy: 0.9683\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.0988 - val_accuracy: 0.9700\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.1126 - val_accuracy: 0.9683\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0889 - val_accuracy: 0.9700\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.1047 - val_accuracy: 0.9667\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.1100 - val_accuracy: 0.9650\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.1069 - val_accuracy: 0.9683\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0288 - accuracy: 0.9892 - val_loss: 0.1082 - val_accuracy: 0.9683\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0208 - accuracy: 0.9917 - val_loss: 0.1087 - val_accuracy: 0.9650\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.1226 - val_accuracy: 0.9617\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.1121 - val_accuracy: 0.9667\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1148 - val_accuracy: 0.9633\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.1269 - val_accuracy: 0.9633\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.1170 - val_accuracy: 0.9667\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.1166 - val_accuracy: 0.9667\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1038 - val_accuracy: 0.9633\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.1257 - val_accuracy: 0.9717\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.1159 - val_accuracy: 0.9683\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0123 - accuracy: 0.9950 - val_loss: 0.1272 - val_accuracy: 0.9650\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.1179 - val_accuracy: 0.9650\n",
      "Epoch 59/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.1179 - val_accuracy: 0.9633\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.1250 - val_accuracy: 0.9700\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.1132 - val_accuracy: 0.9700\n",
      "Epoch 62/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1099 - val_accuracy: 0.9650\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1097 - val_accuracy: 0.9717\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.1230 - val_accuracy: 0.9700\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.1168 - val_accuracy: 0.9683\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.1137 - val_accuracy: 0.9700\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.1272 - val_accuracy: 0.9717\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1077 - val_accuracy: 0.9700\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1348 - val_accuracy: 0.9667\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.1352 - val_accuracy: 0.9717\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.1330 - val_accuracy: 0.9683\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0089 - accuracy: 0.9962 - val_loss: 0.1034 - val_accuracy: 0.9683\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1802 - val_accuracy: 0.9650\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0115 - accuracy: 0.9950 - val_loss: 0.1350 - val_accuracy: 0.9683\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.1063 - val_accuracy: 0.9700\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0125 - accuracy: 0.9942 - val_loss: 0.1237 - val_accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0082 - accuracy: 0.9967 - val_loss: 0.1362 - val_accuracy: 0.9650\n",
      "Epoch 78/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1338 - val_accuracy: 0.9667\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.1300 - val_accuracy: 0.9717\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.1306 - val_accuracy: 0.9700\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1351 - val_accuracy: 0.9667\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.1219 - val_accuracy: 0.9633\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.1324 - val_accuracy: 0.9683\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1244 - val_accuracy: 0.9683\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1353 - val_accuracy: 0.9750\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1493 - val_accuracy: 0.9767\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.1303 - val_accuracy: 0.9750\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1323 - val_accuracy: 0.9750\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1151 - val_accuracy: 0.9700\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.1022 - val_accuracy: 0.9683\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.1090 - val_accuracy: 0.9733\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.1396 - val_accuracy: 0.9717\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.1246 - val_accuracy: 0.9717\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0076 - accuracy: 0.9967 - val_loss: 0.1065 - val_accuracy: 0.9633\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1510 - val_accuracy: 0.9683\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1563 - val_accuracy: 0.9717\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9667\n",
      "Epoch 98/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.1151 - val_accuracy: 0.9683\n",
      "Epoch 99/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1315 - val_accuracy: 0.9683\n",
      "Epoch 100/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.1152 - val_accuracy: 0.9667\n",
      "Epoch 101/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.1482 - val_accuracy: 0.9717\n",
      "Epoch 102/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0046 - accuracy: 0.9975 - val_loss: 0.1380 - val_accuracy: 0.9667\n",
      "Epoch 103/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1577 - val_accuracy: 0.9733\n",
      "Epoch 104/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.1585 - val_accuracy: 0.9733\n",
      "Epoch 105/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.1232 - val_accuracy: 0.9650\n",
      "Epoch 106/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1355 - val_accuracy: 0.9717\n",
      "Epoch 107/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1280 - val_accuracy: 0.9700\n",
      "Epoch 108/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.1279 - val_accuracy: 0.9717\n",
      "Epoch 109/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.1238 - val_accuracy: 0.9683\n",
      "Epoch 110/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1436 - val_accuracy: 0.9683\n",
      "Epoch 111/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1476 - val_accuracy: 0.9717\n",
      "Epoch 112/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1484 - val_accuracy: 0.9667\n",
      "Epoch 113/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.1616 - val_accuracy: 0.9700\n",
      "Epoch 114/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1275 - val_accuracy: 0.9717\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1323 - val_accuracy: 0.9700loss: 0.0024 - accuracy: 0.99\n",
      "Epoch 116/200\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 8.0273e-04 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9700\n",
      "Epoch 117/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.0033 - accuracy: 0.9979 - val_loss: 0.1610 - val_accuracy: 0.9733\n",
      "Epoch 118/200\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.1808 - val_accuracy: 0.9733\n",
      "Epoch 119/200\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1504 - val_accuracy: 0.9700\n",
      "Epoch 120/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.1259 - val_accuracy: 0.9667\n",
      "Epoch 121/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 9.9613e-04 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9733\n",
      "Epoch 122/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1492 - val_accuracy: 0.9683\n",
      "Epoch 123/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1241 - val_accuracy: 0.9683\n",
      "Epoch 124/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.1480 - val_accuracy: 0.9667\n",
      "Epoch 125/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9700\n",
      "Epoch 126/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1632 - val_accuracy: 0.9733\n",
      "Epoch 127/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.1583 - val_accuracy: 0.9717\n",
      "Epoch 128/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9700\n",
      "Epoch 129/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1474 - val_accuracy: 0.9667\n",
      "Epoch 130/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.1319 - val_accuracy: 0.9717\n",
      "Epoch 131/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1735 - val_accuracy: 0.9683\n",
      "Epoch 132/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 0.1484 - val_accuracy: 0.9700\n",
      "Epoch 133/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1526 - val_accuracy: 0.9683\n",
      "Epoch 134/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.1436 - val_accuracy: 0.9633\n",
      "Epoch 135/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1795 - val_accuracy: 0.9683\n",
      "Epoch 136/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1514 - val_accuracy: 0.9700\n",
      "Epoch 137/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1623 - val_accuracy: 0.9733\n",
      "Epoch 138/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1563 - val_accuracy: 0.9717\n",
      "Epoch 139/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1399 - val_accuracy: 0.9717\n",
      "Epoch 140/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.1419 - val_accuracy: 0.9667\n",
      "Epoch 141/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 8.4253e-04 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9733\n",
      "Epoch 142/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.1435 - val_accuracy: 0.9733\n",
      "Epoch 143/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1510 - val_accuracy: 0.9700\n",
      "Epoch 144/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 9.9177e-04 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9700\n",
      "Epoch 145/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1382 - val_accuracy: 0.9717\n",
      "Epoch 146/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1533 - val_accuracy: 0.9683\n",
      "Epoch 147/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1666 - val_accuracy: 0.9683\n",
      "Epoch 148/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1821 - val_accuracy: 0.9683\n",
      "Epoch 149/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1599 - val_accuracy: 0.9700\n",
      "Epoch 150/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1663 - val_accuracy: 0.9683\n",
      "Epoch 151/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.1470 - val_accuracy: 0.9667\n",
      "Epoch 152/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1435 - val_accuracy: 0.9700\n",
      "Epoch 153/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.1570 - val_accuracy: 0.9733\n",
      "Epoch 154/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1393 - val_accuracy: 0.9700\n",
      "Epoch 155/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1462 - val_accuracy: 0.9700\n",
      "Epoch 156/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1498 - val_accuracy: 0.9700\n",
      "Epoch 157/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 5.2650e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9733\n",
      "Epoch 158/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1597 - val_accuracy: 0.9717\n",
      "Epoch 159/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1509 - val_accuracy: 0.9683\n",
      "Epoch 160/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1434 - val_accuracy: 0.9700\n",
      "Epoch 161/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.1372 - val_accuracy: 0.9683\n",
      "Epoch 162/200\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1377 - val_accuracy: 0.9683\n",
      "Epoch 163/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.1835 - val_accuracy: 0.9750\n",
      "Epoch 164/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.1482 - val_accuracy: 0.9700\n",
      "Epoch 165/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.1490 - val_accuracy: 0.9700\n",
      "Epoch 166/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1528 - val_accuracy: 0.9733\n",
      "Epoch 167/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9717\n",
      "Epoch 168/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1569 - val_accuracy: 0.9733\n",
      "Epoch 169/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 8.7989e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9733\n",
      "Epoch 170/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1470 - val_accuracy: 0.9733\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 51ms/step - loss: 2.9104e-04 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9733\n",
      "Epoch 172/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 6.7350e-04 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9733\n",
      "Epoch 173/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.1172 - val_accuracy: 0.9717\n",
      "Epoch 174/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9717\n",
      "Epoch 175/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 3.5340e-04 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9733\n",
      "Epoch 176/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 8.6540e-04 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9717\n",
      "Epoch 177/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 3.6692e-04 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9733\n",
      "Epoch 178/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1667 - val_accuracy: 0.9717\n",
      "Epoch 179/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1504 - val_accuracy: 0.9733\n",
      "Epoch 180/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9717\n",
      "Epoch 181/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 8.0988e-04 - accuracy: 0.9996 - val_loss: 0.1527 - val_accuracy: 0.9700\n",
      "Epoch 182/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.1482 - val_accuracy: 0.9683\n",
      "Epoch 183/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1299 - val_accuracy: 0.9717\n",
      "Epoch 184/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.1412 - val_accuracy: 0.9700\n",
      "Epoch 185/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.1564 - val_accuracy: 0.9617\n",
      "Epoch 186/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 8.3939e-04 - accuracy: 0.9996 - val_loss: 0.1658 - val_accuracy: 0.9733\n",
      "Epoch 187/200\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1788 - val_accuracy: 0.9767\n",
      "Epoch 188/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 7.5592e-04 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9733\n",
      "Epoch 189/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 3.7701e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9717\n",
      "Epoch 190/200\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.1546 - val_accuracy: 0.9650\n",
      "Epoch 191/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1643 - val_accuracy: 0.9667\n",
      "Epoch 192/200\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1802 - val_accuracy: 0.9767\n",
      "Epoch 193/200\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1353 - val_accuracy: 0.9717\n",
      "Epoch 194/200\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 5.5639e-04 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9683\n",
      "Epoch 195/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 5.3738e-04 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9667\n",
      "Epoch 196/200\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1997 - val_accuracy: 0.9750\n",
      "Epoch 197/200\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.2473 - val_accuracy: 0.9750\n",
      "Epoch 198/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 8.0356e-04 - accuracy: 0.9996 - val_loss: 0.2508 - val_accuracy: 0.9733\n",
      "Epoch 199/200\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.1784 - val_accuracy: 0.9733\n",
      "Epoch 200/200\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1332 - val_accuracy: 0.9717\n",
      "--- 614.6191058158875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, epochs = 200, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0f441",
   "metadata": {},
   "source": [
    "\n",
    "30.509965896606445 seconds --- 30 epochs , 0.9683 acc , 16x16 Greyscale image <br>\n",
    "86.94418954849243 seconds --- 30 epochs , 0.9783 acc , 32x32 Greyscale image <br>\n",
    "169.6840739250183 seconds --- 60 epochs , 0.9667 acc , 32x32 Greyscale image <br>\n",
    "335.7380225658417 seconds --- 30 epochs , 0.9700 acc , 64x64 Greyscale image <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f29949ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "test_data = []\n",
    "test_result = []\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"test_dataset/test/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"test_dataset/test/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "test_encoder = OneHotEncoder()\n",
    "test_encoder.fit([[0], [1]]) \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/no_tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L') # not an RGB image so import as greyscale\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    test_data.append(np.array(img))\n",
    "    test_result.append(test_encoder.transform([[0]]).toarray())\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    test_data.append(np.array(img))\n",
    "    test_result.append(test_encoder.transform([[1]]).toarray())   \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64fbadd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[1., 0.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]]), array([[0., 1.]])]\n",
      "[[[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array(test_data)\n",
    "#print(test_data.shape)\n",
    "print(test_result)\n",
    "test_result = np.array(test_result)\n",
    "print(test_result)\n",
    "test_result = test_result.reshape(200,2)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d48b716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_data, test_result, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51ff6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09202636033296585, 0.9850000143051147]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29914eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_labels['label'] = np.where(tumor_labels['label'] == \"no_tumor\", \"no tumor\", tumor_labels['label'])\n",
    "tumor_labels['label'] = np.where(tumor_labels['label'] != \"no tumor\", \"tumor\", tumor_labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56e0622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Tumor dataset - probability')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(tumor_labels[tumor_labels.columns[1]], stat=\"probability\").set_title('Tumor dataset - probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c82c202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image', 'label.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = 2\n",
    "input_shape = (512,512,1)\n",
    "image_dir = \"dataset/\"\n",
    "os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65c8d600",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6916/1335977003.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_generator=datagen.flow_from_dataframe(\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtumor_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=tumor_labels,\n",
    "directory=image_dir,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "447e8311",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.preprocessing' has no attribute 'flow_from_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6916/3521237991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtumor_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.preprocessing' has no attribute 'flow_from_dataframe'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator=tf.keras.preprocessing.flow_from_dataframe(dataframe=tumor_labels, directory=image_dir, x_col=\"id\", y_col=\"label\", class_mode=\"categorical\", target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4e2cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/split_data/binary/\",\n",
    "    labels=\"inferred\",\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c82c0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17312/514710854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvgg16_weight_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m base_model = VGG16(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvgg16_weight_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    114\u001b[0m   \"\"\"\n\u001b[0;32m    115\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;34m'The `weights` argument should be either '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
     ]
    }
   ],
   "source": [
    "vgg16_weight_path = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model = VGG16(\n",
    "    weights=vgg16_weight_path,\n",
    "    include_top=False, \n",
    "    input_shape=(512,512) + (3,)\n",
    ")\n",
    "\n",
    "\n",
    "# basic model for now \n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(3000, 512,512)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile()\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc680979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 1 classes.\n",
      "Found 3000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        \"dataset/\",\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        # Since we use categorical_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        \"dataset/\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
