{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d557e5",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4462fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "# Machine learning (non deep learning)\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#misc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e2fa",
   "metadata": {},
   "source": [
    "Read in csv data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e5e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_labels = pd.read_csv(\"dataset/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7e2f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>pituitary_tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name             label\n",
       "0     IMAGE_0000.jpg  meningioma_tumor\n",
       "1     IMAGE_0001.jpg          no_tumor\n",
       "2     IMAGE_0002.jpg  meningioma_tumor\n",
       "3     IMAGE_0003.jpg      glioma_tumor\n",
       "4     IMAGE_0004.jpg  meningioma_tumor\n",
       "...              ...               ...\n",
       "2995  IMAGE_2995.jpg          no_tumor\n",
       "2996  IMAGE_2996.jpg  meningioma_tumor\n",
       "2997  IMAGE_2997.jpg      glioma_tumor\n",
       "2998  IMAGE_2998.jpg      glioma_tumor\n",
       "2999  IMAGE_2999.jpg   pituitary_tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ff6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tumor_labels)):\n",
    "    if (tumor_labels.iloc[i][\"label\"] == \"no_tumor\"):\n",
    "        tumor_labels.iloc[i][\"label\"] = \"no tumor\"\n",
    "    else: \n",
    "        tumor_labels.iloc[i][\"label\"] = \"tumor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5ae84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name     label\n",
       "0     IMAGE_0000.jpg     tumor\n",
       "1     IMAGE_0001.jpg  no tumor\n",
       "2     IMAGE_0002.jpg     tumor\n",
       "3     IMAGE_0003.jpg     tumor\n",
       "4     IMAGE_0004.jpg     tumor\n",
       "...              ...       ...\n",
       "2995  IMAGE_2995.jpg  no tumor\n",
       "2996  IMAGE_2996.jpg     tumor\n",
       "2997  IMAGE_2997.jpg     tumor\n",
       "2998  IMAGE_2998.jpg     tumor\n",
       "2999  IMAGE_2999.jpg     tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d892ca2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"dataset/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"dataset/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[1]]).toarray())\n",
    "        \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/no_tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf006ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "result = np.array(result)\n",
    "result = result.reshape(3000,2)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abb2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(32, 32, 1), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',  metrics = ['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ecb8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "60/60 [==============================] - 4s 51ms/step - loss: 0.9430 - accuracy: 0.8292 - val_loss: 0.2522 - val_accuracy: 0.9183\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.4258 - accuracy: 0.8788 - val_loss: 0.6994 - val_accuracy: 0.7167\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.3149 - accuracy: 0.8888 - val_loss: 0.2862 - val_accuracy: 0.9050\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.2354 - accuracy: 0.9029 - val_loss: 0.2271 - val_accuracy: 0.9200\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.2068 - accuracy: 0.9179 - val_loss: 0.1967 - val_accuracy: 0.9250\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.1918 - accuracy: 0.9267 - val_loss: 0.1619 - val_accuracy: 0.9250\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.1667 - accuracy: 0.9283 - val_loss: 0.1397 - val_accuracy: 0.9383\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1632 - accuracy: 0.9358 - val_loss: 0.1063 - val_accuracy: 0.9567\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.1439 - accuracy: 0.9429 - val_loss: 0.1160 - val_accuracy: 0.9567\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.1371 - accuracy: 0.9429 - val_loss: 0.1108 - val_accuracy: 0.9533\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 0.1304 - accuracy: 0.9496 - val_loss: 0.1065 - val_accuracy: 0.9583\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.1230 - accuracy: 0.9513 - val_loss: 0.1194 - val_accuracy: 0.9483\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1135 - accuracy: 0.9538 - val_loss: 0.1045 - val_accuracy: 0.9583\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1044 - accuracy: 0.9600 - val_loss: 0.1134 - val_accuracy: 0.9550\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0978 - accuracy: 0.9646 - val_loss: 0.1357 - val_accuracy: 0.9483\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.1210 - accuracy: 0.9492 - val_loss: 0.1071 - val_accuracy: 0.9650\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0973 - accuracy: 0.9621 - val_loss: 0.1220 - val_accuracy: 0.9567\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0820 - accuracy: 0.9654 - val_loss: 0.0998 - val_accuracy: 0.9633\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0659 - accuracy: 0.9746 - val_loss: 0.1054 - val_accuracy: 0.9667\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0822 - accuracy: 0.9679 - val_loss: 0.1157 - val_accuracy: 0.9600ccura\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0639 - accuracy: 0.9750 - val_loss: 0.0970 - val_accuracy: 0.9633\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0603 - accuracy: 0.9762 - val_loss: 0.0903 - val_accuracy: 0.9633\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0609 - accuracy: 0.9758 - val_loss: 0.0911 - val_accuracy: 0.9633\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0646 - accuracy: 0.9750 - val_loss: 0.1029 - val_accuracy: 0.9667\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.1035 - val_accuracy: 0.9717\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0500 - accuracy: 0.9796 - val_loss: 0.0940 - val_accuracy: 0.9733\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0497 - accuracy: 0.9796 - val_loss: 0.1190 - val_accuracy: 0.9650\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0462 - accuracy: 0.9833 - val_loss: 0.0944 - val_accuracy: 0.9700\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0469 - accuracy: 0.9821 - val_loss: 0.1014 - val_accuracy: 0.9717\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0423 - accuracy: 0.9837 - val_loss: 0.0921 - val_accuracy: 0.9700\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.1049 - val_accuracy: 0.9700\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0280 - accuracy: 0.9892 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 0.0758 - val_accuracy: 0.9750\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.1108 - val_accuracy: 0.9733\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.1040 - val_accuracy: 0.9700\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1300 - val_accuracy: 0.9717\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0247 - accuracy: 0.9904 - val_loss: 0.1158 - val_accuracy: 0.9700\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.1131 - val_accuracy: 0.9700\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0895 - val_accuracy: 0.9717\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 0.1036 - val_accuracy: 0.9750\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0217 - accuracy: 0.9912 - val_loss: 0.1286 - val_accuracy: 0.9717\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0276 - accuracy: 0.9904 - val_loss: 0.1429 - val_accuracy: 0.9667\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0203 - accuracy: 0.9912 - val_loss: 0.1083 - val_accuracy: 0.9717\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0200 - accuracy: 0.9912 - val_loss: 0.1057 - val_accuracy: 0.9700\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.0991 - val_accuracy: 0.9717\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.1234 - val_accuracy: 0.9733\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.1377 - val_accuracy: 0.9750\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.0995 - val_accuracy: 0.9733\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.1005 - val_accuracy: 0.9733\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.1113 - val_accuracy: 0.9717\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1171 - val_accuracy: 0.9700\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.1084 - val_accuracy: 0.9750\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0164 - accuracy: 0.9929 - val_loss: 0.1060 - val_accuracy: 0.9767\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0942 - val_accuracy: 0.9750\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.1068 - val_accuracy: 0.9783\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.1162 - val_accuracy: 0.9767\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1123 - val_accuracy: 0.9783\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1361 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1383 - val_accuracy: 0.9750\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1225 - val_accuracy: 0.9750\n",
      "--- 181.19884276390076 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, epochs = 60, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0f441",
   "metadata": {},
   "source": [
    "\n",
    "30.509965896606445 seconds --- 30 epochs , 0.9683 acc , 16x16 Greyscale image <br>\n",
    "86.94418954849243 seconds --- 30 epochs , 0.9783 acc , 32x32 Greyscale image <br>\n",
    "169.6840739250183 seconds --- 60 epochs , 0.9667 acc , 32x32 Greyscale image <br>\n",
    "335.7380225658417 seconds --- 30 epochs , 0.9700 acc , 64x64 Greyscale image <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f856c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "test_data = []\n",
    "test_result = []\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"test_dataset/test/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"test_dataset/test/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/no_tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L') # not an RGB image so import as greyscale\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    test_data.append(np.array(img))\n",
    "    test_result.append(0)\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    test_data.append(np.array(img))\n",
    "    test_result.append(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3204546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f65f4d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n        self.compiled_loss(\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14392/880792878.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n        self.compiled_loss(\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(np.asarray(test_data), np.asarray(test_result), verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29914eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_labels['label'] = np.where(tumor_labels['label'] == \"no_tumor\", \"no tumor\", tumor_labels['label'])\n",
    "tumor_labels['label'] = np.where(tumor_labels['label'] != \"no tumor\", \"tumor\", tumor_labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56e0622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Tumor dataset - probability')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(tumor_labels[tumor_labels.columns[1]], stat=\"probability\").set_title('Tumor dataset - probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c82c202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image', 'label.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = 2\n",
    "input_shape = (512,512,1)\n",
    "image_dir = \"dataset/\"\n",
    "os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65c8d600",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6916/1335977003.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_generator=datagen.flow_from_dataframe(\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtumor_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=tumor_labels,\n",
    "directory=image_dir,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "447e8311",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.preprocessing' has no attribute 'flow_from_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6916/3521237991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtumor_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.preprocessing' has no attribute 'flow_from_dataframe'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator=tf.keras.preprocessing.flow_from_dataframe(dataframe=tumor_labels, directory=image_dir, x_col=\"id\", y_col=\"label\", class_mode=\"categorical\", target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4e2cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/split_data/binary/\",\n",
    "    labels=\"inferred\",\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c82c0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17312/514710854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvgg16_weight_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m base_model = VGG16(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvgg16_weight_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    114\u001b[0m   \"\"\"\n\u001b[0;32m    115\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;34m'The `weights` argument should be either '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
     ]
    }
   ],
   "source": [
    "vgg16_weight_path = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model = VGG16(\n",
    "    weights=vgg16_weight_path,\n",
    "    include_top=False, \n",
    "    input_shape=(512,512) + (3,)\n",
    ")\n",
    "\n",
    "\n",
    "# basic model for now \n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(3000, 512,512)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile()\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc680979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 1 classes.\n",
      "Found 3000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        \"dataset/\",\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        # Since we use categorical_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        \"dataset/\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
