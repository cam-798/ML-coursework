{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d557e5",
   "metadata": {},
   "source": [
    "<h5>Importing libraries</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4462fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "# Machine learning (non deep learning)\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#misc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeda59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name     label\n",
       "0     IMAGE_0000.jpg     tumor\n",
       "1     IMAGE_0001.jpg  no_tumor\n",
       "2     IMAGE_0002.jpg     tumor\n",
       "3     IMAGE_0003.jpg     tumor\n",
       "4     IMAGE_0004.jpg     tumor\n",
       "...              ...       ...\n",
       "2995  IMAGE_2995.jpg  no_tumor\n",
       "2996  IMAGE_2996.jpg     tumor\n",
       "2997  IMAGE_2997.jpg     tumor\n",
       "2998  IMAGE_2998.jpg     tumor\n",
       "2999  IMAGE_2999.jpg     tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_labels = pd.read_csv(\"dataset/label.csv\")\n",
    "for i in range(len(tumor_labels)):\n",
    "    if (tumor_labels.iloc[i][\"label\"] == \"no_tumor\"):\n",
    "        tumor_labels.iloc[i][\"label\"] = \"no_tumor\"\n",
    "    else: \n",
    "        tumor_labels.iloc[i][\"label\"] = \"tumor\"\n",
    "tumor_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e2fa",
   "metadata": {},
   "source": [
    "<h5>Read in images into numpy arrays and record type of tumor with one hot encoder</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d892ca2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# path to train tumor files\n",
    "train_tumor_image_dir = \"datagen/train/tumor/\"\n",
    "train_tumor_files = os.listdir(train_tumor_image_dir)\n",
    "\n",
    "# path to train tumor files\n",
    "train_no_tumor_image_dir = \"datagen/train/no_tumor/\"\n",
    "train_no_tumor_files = os.listdir(train_no_tumor_image_dir)\n",
    "\n",
    "# path to test tumor files\n",
    "test_tumor_image_dir = \"datagen/test/tumor/\"\n",
    "test_tumor_files = os.listdir(test_tumor_image_dir)\n",
    "\n",
    "# path to test non tumor files\n",
    "test_no_tumor_image_dir = \"datagen/test/no_tumor/\"\n",
    "test_no_tumor_files = os.listdir(test_no_tumor_image_dir)\n",
    "\n",
    "\n",
    "## train\n",
    "for file in train_tumor_files:\n",
    "    temp_file_path = \"datagen/train/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[1]]).toarray())\n",
    "        \n",
    "\n",
    "for file in train_no_tumor_files:\n",
    "    temp_file_path = \"datagen/train/no_tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[0]]).toarray())\n",
    "\n",
    "    \n",
    "## test\n",
    "\n",
    "for file in test_tumor_files:\n",
    "    temp_file_path = \"datagen/test/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[1]]).toarray())\n",
    "        \n",
    "\n",
    "for file in test_no_tumor_files:\n",
    "    temp_file_path = \"datagen/test/no_tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[0]]).toarray())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154a49d",
   "metadata": {},
   "source": [
    "<h5>Reshape data and split between test and train data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf006ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "result = np.array(result)\n",
    "result = result.reshape(3000,2)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data, result , test_size=0.2, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514903d",
   "metadata": {},
   "source": [
    "<h5>Build the CNN model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abb2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(32, 32, 1), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',  metrics = ['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76160eff",
   "metadata": {},
   "source": [
    "<h5>Train the model and record time to train</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ecb8cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 1.0885 - accuracy: 0.8000 - val_loss: 1.3985 - val_accuracy: 0.3100\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.5607 - accuracy: 0.8308 - val_loss: 0.5424 - val_accuracy: 0.8017\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.3880 - accuracy: 0.8592 - val_loss: 0.3323 - val_accuracy: 0.8583\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.3434 - accuracy: 0.8675 - val_loss: 0.3148 - val_accuracy: 0.8617\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.2899 - accuracy: 0.8813 - val_loss: 0.3060 - val_accuracy: 0.8650\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.2933 - accuracy: 0.8883 - val_loss: 0.2783 - val_accuracy: 0.8750\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2709 - accuracy: 0.8879 - val_loss: 0.2859 - val_accuracy: 0.8600\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2459 - accuracy: 0.8946 - val_loss: 0.2610 - val_accuracy: 0.8683\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2443 - accuracy: 0.8913 - val_loss: 0.2803 - val_accuracy: 0.8683\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2360 - accuracy: 0.9058 - val_loss: 0.2544 - val_accuracy: 0.8800\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2116 - accuracy: 0.9175 - val_loss: 0.2935 - val_accuracy: 0.8717\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2056 - accuracy: 0.9108 - val_loss: 0.3519 - val_accuracy: 0.8583\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.2093 - accuracy: 0.9179 - val_loss: 0.2603 - val_accuracy: 0.8750\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1846 - accuracy: 0.9308 - val_loss: 0.2617 - val_accuracy: 0.8817\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1839 - accuracy: 0.9250 - val_loss: 0.3266 - val_accuracy: 0.8733\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1755 - accuracy: 0.9333 - val_loss: 0.3483 - val_accuracy: 0.8767\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1804 - accuracy: 0.9254 - val_loss: 0.2665 - val_accuracy: 0.8817\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1513 - accuracy: 0.9417 - val_loss: 0.2822 - val_accuracy: 0.8783\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1525 - accuracy: 0.9388 - val_loss: 0.2832 - val_accuracy: 0.8783\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1393 - accuracy: 0.9450 - val_loss: 0.3411 - val_accuracy: 0.8833\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1456 - accuracy: 0.9400 - val_loss: 0.3057 - val_accuracy: 0.8783\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1373 - accuracy: 0.9508 - val_loss: 0.3224 - val_accuracy: 0.8717\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1153 - accuracy: 0.9542 - val_loss: 0.2836 - val_accuracy: 0.8783\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1182 - accuracy: 0.9525 - val_loss: 0.3159 - val_accuracy: 0.8717\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1104 - accuracy: 0.9579 - val_loss: 0.3455 - val_accuracy: 0.8733\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.1073 - accuracy: 0.9592 - val_loss: 0.2956 - val_accuracy: 0.8750\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0973 - accuracy: 0.9642 - val_loss: 0.2931 - val_accuracy: 0.8783\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0998 - accuracy: 0.9617 - val_loss: 0.4469 - val_accuracy: 0.8683\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0882 - accuracy: 0.9646 - val_loss: 0.3053 - val_accuracy: 0.8783\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0913 - accuracy: 0.9671 - val_loss: 0.2881 - val_accuracy: 0.8833\n",
      "--- 95.08248782157898 seconds ---\n"
     ]
    }
   ],
   "source": [
    "bs = 30\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, epochs = 300, batch_size = bs, verbose=1, callbacks=[callback], validation_data=(x_test, y_test))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0f441",
   "metadata": {},
   "source": [
    "<h6>Some basic results recording, just for keeping information to hand</h6>\n",
    "\n",
    "30.509965896606445 seconds --- 30 epochs , 0.9683 acc , 16x16 Greyscale image <br>\n",
    "86.94418954849243 seconds --- 30 epochs , 0.9783 acc , 32x32 Greyscale image <br>\n",
    "169.6840739250183 seconds --- 60 epochs , 0.9667 acc , 32x32 Greyscale image <br>\n",
    "335.7380225658417 seconds --- 30 epochs , 0.9700 acc , 64x64 Greyscale image <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b40e7",
   "metadata": {},
   "source": [
    "<h5> Print model history </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679a4d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0884978771209717,\n",
       "  0.5607299208641052,\n",
       "  0.3880394697189331,\n",
       "  0.3433830738067627,\n",
       "  0.2898510694503784,\n",
       "  0.29330453276634216,\n",
       "  0.270906001329422,\n",
       "  0.24593757092952728,\n",
       "  0.2443082183599472,\n",
       "  0.23600827157497406,\n",
       "  0.21157734096050262,\n",
       "  0.20560288429260254,\n",
       "  0.20933684706687927,\n",
       "  0.18460585176944733,\n",
       "  0.1838633418083191,\n",
       "  0.17545665800571442,\n",
       "  0.18035338819026947,\n",
       "  0.1512891799211502,\n",
       "  0.1524948924779892,\n",
       "  0.13926458358764648,\n",
       "  0.14563655853271484,\n",
       "  0.13732443749904633,\n",
       "  0.1152794286608696,\n",
       "  0.11817266047000885,\n",
       "  0.11041253060102463,\n",
       "  0.1072564423084259,\n",
       "  0.09733934700489044,\n",
       "  0.09979616850614548,\n",
       "  0.08815982937812805,\n",
       "  0.09131615608930588],\n",
       " 'accuracy': [0.800000011920929,\n",
       "  0.8308333158493042,\n",
       "  0.85916668176651,\n",
       "  0.8675000071525574,\n",
       "  0.8812500238418579,\n",
       "  0.8883333206176758,\n",
       "  0.8879166841506958,\n",
       "  0.8945833444595337,\n",
       "  0.8912500143051147,\n",
       "  0.9058333039283752,\n",
       "  0.9175000190734863,\n",
       "  0.9108333587646484,\n",
       "  0.9179166555404663,\n",
       "  0.9308333396911621,\n",
       "  0.925000011920929,\n",
       "  0.9333333373069763,\n",
       "  0.9254166483879089,\n",
       "  0.9416666626930237,\n",
       "  0.9387500286102295,\n",
       "  0.9449999928474426,\n",
       "  0.9399999976158142,\n",
       "  0.9508333206176758,\n",
       "  0.9541666507720947,\n",
       "  0.9524999856948853,\n",
       "  0.9579166769981384,\n",
       "  0.9591666460037231,\n",
       "  0.9641666412353516,\n",
       "  0.9616666436195374,\n",
       "  0.9645833373069763,\n",
       "  0.9670833349227905],\n",
       " 'val_loss': [1.3984708786010742,\n",
       "  0.5424345135688782,\n",
       "  0.33225157856941223,\n",
       "  0.3147848844528198,\n",
       "  0.3060217797756195,\n",
       "  0.278322696685791,\n",
       "  0.28593504428863525,\n",
       "  0.26096662878990173,\n",
       "  0.2802969813346863,\n",
       "  0.2543819546699524,\n",
       "  0.29351142048835754,\n",
       "  0.35187697410583496,\n",
       "  0.2602941393852234,\n",
       "  0.26172778010368347,\n",
       "  0.32662785053253174,\n",
       "  0.3482900857925415,\n",
       "  0.26645156741142273,\n",
       "  0.28219425678253174,\n",
       "  0.28316524624824524,\n",
       "  0.3410569727420807,\n",
       "  0.3056643307209015,\n",
       "  0.3224124610424042,\n",
       "  0.2836468815803528,\n",
       "  0.3158597946166992,\n",
       "  0.3454902768135071,\n",
       "  0.29560622572898865,\n",
       "  0.29310885071754456,\n",
       "  0.4469163119792938,\n",
       "  0.3053183853626251,\n",
       "  0.2881490886211395],\n",
       " 'val_accuracy': [0.3100000023841858,\n",
       "  0.8016666769981384,\n",
       "  0.8583333492279053,\n",
       "  0.8616666793823242,\n",
       "  0.8650000095367432,\n",
       "  0.875,\n",
       "  0.8600000143051147,\n",
       "  0.8683333396911621,\n",
       "  0.8683333396911621,\n",
       "  0.8799999952316284,\n",
       "  0.871666669845581,\n",
       "  0.8583333492279053,\n",
       "  0.875,\n",
       "  0.8816666603088379,\n",
       "  0.8733333349227905,\n",
       "  0.8766666650772095,\n",
       "  0.8816666603088379,\n",
       "  0.878333330154419,\n",
       "  0.878333330154419,\n",
       "  0.8833333253860474,\n",
       "  0.878333330154419,\n",
       "  0.871666669845581,\n",
       "  0.878333330154419,\n",
       "  0.871666669845581,\n",
       "  0.8733333349227905,\n",
       "  0.875,\n",
       "  0.878333330154419,\n",
       "  0.8683333396911621,\n",
       "  0.878333330154419,\n",
       "  0.8833333253860474]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2958ad",
   "metadata": {},
   "source": [
    "<h5>Read in the validation data in the same way we read in the training and testing data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79dfbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "validation_data = []\n",
    "validation_result = []\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"test_dataset/test/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"test_dataset/test/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "test_encoder = OneHotEncoder()\n",
    "test_encoder.fit([[0], [1]]) \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/no_tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L') # not an RGB image so import as greyscale\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    validation_data.append(np.array(img))\n",
    "    validation_result.append(test_encoder.transform([[0]]).toarray())\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"test_dataset/test/split_data/binary/tumor/\"+file\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    validation_data.append(np.array(img))\n",
    "    validation_result.append(test_encoder.transform([[1]]).toarray())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e4669",
   "metadata": {},
   "source": [
    "<h5>reshape validation data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e137a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = np.array(validation_data)\n",
    "validation_result = np.array(validation_result)\n",
    "validation_result = validation_result.reshape(200,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d2ac6",
   "metadata": {},
   "source": [
    "<h5>Get and print scores</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d922789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(validation_data, validation_result, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8322052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.30010929703712463\n",
      "test accuracy: 0.8949999809265137\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss: \" + str(scores[0]))\n",
    "print(\"test accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "30b1e8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 0.07656975090503693, 0.9750000238418579],\n",
       " [30, 0.06190032511949539, 0.9800000190734863],\n",
       " [50, 0.04844776168465614, 0.9800000190734863],\n",
       " [70, 0.06202394515275955, 0.9649999737739563],\n",
       " [90, 0.05173724144697189, 0.9750000238418579],\n",
       " [110, 0.05443058907985687, 0.9850000143051147],\n",
       " [130, 0.04711779206991196, 0.9800000190734863],\n",
       " [150, 0.04425444081425667, 0.9850000143051147],\n",
       " [170, 0.046532295644283295, 0.9750000238418579],\n",
       " [190, 0.039801206439733505, 0.9900000095367432],\n",
       " [210, 0.05233008414506912, 0.9750000238418579],\n",
       " [230, 0.042826972901821136, 0.9850000143051147],\n",
       " [250, 0.05040019005537033, 0.9850000143051147],\n",
       " [270, 0.04743853583931923, 0.9800000190734863],\n",
       " [290, 0.04829291254281998, 0.9750000238418579],\n",
       " [310, 0.04591016843914986, 0.9850000143051147],\n",
       " [8, 0.056518469005823135, 0.9850000143051147],\n",
       " [8, 0.05424250662326813, 0.9800000190734863],\n",
       " [8, 0.08594222366809845, 0.9649999737739563],\n",
       " [40, 0.06024970859289169, 0.9800000190734863]]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_batch_array "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
