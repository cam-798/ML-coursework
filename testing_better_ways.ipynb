{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8f517d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of random rotation image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "import imageio\n",
    "# Machine learning (non deep learning)\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#misc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ad58506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"dataset/split_data/binary/merged/validation/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9efbff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = os.listdir(\"dataset/split_data/binary/merged/validation\")\n",
    "\n",
    "for i in range(len(images_list)):\n",
    "    datagen = ImageDataGenerator(rotation_range = 90, width_shift_range=0.25, height_shift_range=0.25, shear_range=0.25, zoom_range=0.25)\n",
    "    image_path = \"dataset/image/\"+images_list[i]\n",
    "    image = np.expand_dims(imageio.imread(image_path), 0)\n",
    "    save_here = \"datagen/test/\"\n",
    "    datagen.fit(image)\n",
    "    for x, val in zip(datagen.flow(image,                    #image we chose\n",
    "            save_to_dir=save_here, \n",
    "            save_prefix =images_list[i],#this is where we figure out where to save\n",
    "            save_format='jpg'),range(0)):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13fab99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reshape_size = (32,32)\n",
    "\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# path to tumor files\n",
    "tumor_image_dir = \"dataset/split_data/binary/tumor\"\n",
    "tumor_files = os.listdir(tumor_image_dir)\n",
    "\n",
    "# path to non tumor files\n",
    "no_tumor_image_dir = \"dataset/split_data/binary/no_tumor\"\n",
    "no_tumor_files = os.listdir(no_tumor_image_dir)\n",
    "\n",
    "for file in tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[1]]).toarray())\n",
    "        \n",
    "\n",
    "for file in no_tumor_files:\n",
    "    temp_file_path = \"dataset/split_data/binary/no_tumor/\"+file\n",
    "    #print(\"path is \" +temp_file_path)\n",
    "    img = Image.open(temp_file_path).convert('L')\n",
    "    img = img.resize(img_reshape_size)\n",
    "    img = np.array(img)\n",
    "    data.append(np.array(img))\n",
    "    result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ccaaa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "result = np.array(result)\n",
    "result = result.reshape(3000,2)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7a7bed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name     label\n",
       "0     IMAGE_0000.jpg     tumor\n",
       "1     IMAGE_0001.jpg  no tumor\n",
       "2     IMAGE_0002.jpg     tumor\n",
       "3     IMAGE_0003.jpg     tumor\n",
       "4     IMAGE_0004.jpg     tumor\n",
       "...              ...       ...\n",
       "2995  IMAGE_2995.jpg  no tumor\n",
       "2996  IMAGE_2996.jpg     tumor\n",
       "2997  IMAGE_2997.jpg     tumor\n",
       "2998  IMAGE_2998.jpg     tumor\n",
       "2999  IMAGE_2999.jpg     tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_labels = pd.read_csv(\"dataset/label.csv\")\n",
    "for i in range(len(tumor_labels)):\n",
    "    if (tumor_labels.iloc[i][\"label\"] == \"no_tumor\"):\n",
    "        tumor_labels.iloc[i][\"label\"] = \"no tumor\"\n",
    "    else: \n",
    "        tumor_labels.iloc[i][\"label\"] = \"tumor\"\n",
    "tumor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9f5da210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(validation_split = 0.2, rotation_range = 90, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, rescale=(1/255))\n",
    "\n",
    "# prepare iterator\n",
    "data = datagen.flow_from_dataframe(tumor_labels, directory=\"dataset/image/\", x_col=\"file_name\", y_col=\"label\", shuffle=False, color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b2c2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(32, 32, 1), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',  metrics = ['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9575a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid={\"C\":[0.001,0.01,0.1,1],\"gamma\":[0.01,0.1,1,10],\"kernel\":[\"rbf\",\"sigmoid\",\"poly\"]}\n",
    "param_grid={\"C\":[0.1],\"gamma\":[0.1,1],\"kernel\":[\"rbf\"]}\n",
    "\n",
    "svc=svm.SVC(probability=True)\n",
    "model=GridSearchCV(svc,param_grid, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e03f4257",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[2048,2] labels_size=[32,2]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5009)\n]] [Op:__inference_train_function_5505]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\Camer\\AppData\\Local\\Temp/ipykernel_13152/2961452684.py\", line 1, in <module>\n>>>     model.fit(data)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 5009, in categorical_crossentropy\n>>>     return tf.nn.softmax_cross_entropy_with_logits(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13152/2961452684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[2048,2] labels_size=[32,2]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5009)\n]] [Op:__inference_train_function_5505]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\Camer\\AppData\\Local\\Temp/ipykernel_13152/2961452684.py\", line 1, in <module>\n>>>     model.fit(data)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 5009, in categorical_crossentropy\n>>>     return tf.nn.softmax_cross_entropy_with_logits(\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb477f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2ea14474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 validated image filenames belonging to 2 classes.\n",
      "Found 600 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split = 0.2, rotation_range = 90, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2)\n",
    "\n",
    "train = datagen.flow_from_dataframe(tumor_labels, target_size=(32,32), directory=\"dataset/image/\", x_col=\"file_name\", y_col=\"label\", shuffle=False, color_mode=\"grayscale\", subset=\"training\")\n",
    "validation = datagen.flow_from_dataframe(tumor_labels, target_size=(32,32), directory=\"dataset/image/\", x_col=\"file_name\", y_col=\"label\", shuffle=False, color_mode=\"grayscale\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c74fc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1ef085be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 150, 150, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='input_13'), name='input_13', description=\"created by layer 'input_13'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f43fc728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model_3\" (type Functional).\n    \n    Input 0 of layer \"xception\" is incompatible with the layer: expected shape=(None, 150, 150, 3), found shape=(None, 32, 32, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13152/319129745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               metrics=[keras.metrics.BinaryAccuracy()])\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\users\\camer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model_3\" (type Functional).\n    \n    Input 0 of layer \"xception\" is incompatible with the layer: expected shape=(None, 150, 150, 3), found shape=(None, 32, 32, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "model.fit(train, epochs=20, validation_data=validation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
